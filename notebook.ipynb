{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acabac3-1319-441d-81b3-2e1a6f7f36ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to install the necessary packages\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "def install_if_needed(package, version):\n",
    "    '''Function to ensure that the libraries used are consistent to avoid errors.'''\n",
    "    try:\n",
    "        pkg = pkg_resources.get_distribution(package)\n",
    "        if pkg.version != version:\n",
    "            raise pkg_resources.VersionConflict(pkg, version)\n",
    "    except (pkg_resources.DistributionNotFound, pkg_resources.VersionConflict):\n",
    "        subprocess.check_call([\"pip\", \"install\", f\"{package}=={version}\"])\n",
    "\n",
    "install_if_needed(\"langchain-core\", \"0.3.18\")\n",
    "install_if_needed(\"langchain-openai\", \"0.2.8\")\n",
    "install_if_needed(\"langchain-community\", \"0.3.7\")\n",
    "install_if_needed(\"unstructured\", \"0.14.4\")\n",
    "install_if_needed(\"langchain-chroma\", \"0.1.4\")\n",
    "install_if_needed(\"langchain-text-splitters\", \"0.3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61baf413-6464-4c1c-a52d-b3764c124602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key to a variable\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "# Import the required packages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed58c70-1315-409c-a590-a4c7af3cad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HTML as a LangChain document loader\n",
    "loader = UnstructuredHTMLLoader(file_path=\"data/mg-zs-warning-messages.html\")\n",
    "car_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636184c7-8491-4bcb-93c5-6c22dd6f8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RecursiveCharacterTextSplitter to make chunks of HTML text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e0398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split GDPR HTML\n",
    "splits = text_splitter.split_documents(car_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f2c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Chunk 1 (Length: 782 chars) ===\n",
      "Warning Message Procedure Cruise Control Fault Indicates that the cruise control system has detected a fault. Please consult an MG Authorised Repairer as soon as possible. Active Speed Limiter Fault I...\n",
      "...\n",
      "\n",
      "\n",
      "=== Chunk 2 (Length: 652 chars) ===\n",
      "Warning Message Procedure Low Oil Pressure Indicates that the oil pressure is too low, which may result in severe engine damage. As soon as safety permits, stop the car, switch off the engine and chec...\n",
      "...\n",
      "\n",
      "\n",
      "=== Chunk 3 (Length: 613 chars) ===\n",
      "Warning Message Procedure Stop Start System Fault Indicates that the Stop/Start intelligent fuel saving system has detected a fault. Please consult an MG Authorised Repairer as soon as possible. Clutc...\n",
      "...\n",
      "\n",
      "\n",
      "=== Chunk 4 (Length: 491 chars) ===\n",
      "Warning Message Procedure Start Stop Button Fault Indicates that the Start Stop button has detected a fault. Please consult an MG Authorised Repairer immediately. Passive Entry Fault Indicates that th...\n",
      "...\n",
      "\n",
      "\n",
      "=== Chunk 5 (Length: 604 chars) ===\n",
      "Warning Message Procedure Brake Fault Indicates that the brake fluid could be low or a fault has been detected in the Electronic Brake-force Distribution (EBD) system. As soon as safety permits, stop ...\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# After splitting, print each chunk with visible separators\n",
    "for i, chunk in enumerate(splits[:5]):  # Show first 5 chunks for demo\n",
    "    print(f\"\\n\\n=== Chunk {i+1} (Length: {len(chunk.page_content)} chars) ===\")\n",
    "    print(chunk.page_content[:200] + \"...\" if len(chunk.page_content) > 200 else chunk.page_content)  # Show preview\n",
    "    print(\"...\")  # Indicates continuation if truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma vectorstore with documents as splits and using OpenAIEmbeddings\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(openai_api_key=os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c5b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup vectorstore as retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RAG prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat-based LLM with 0 temperature and using gpt-4o-mini\n",
    "model = ChatOpenAI(openai_api_key=openai_api_key, model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca85e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize query\n",
    "query = \"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3feae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the query\n",
    "answer = rag_chain.invoke(query).content\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TCenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
